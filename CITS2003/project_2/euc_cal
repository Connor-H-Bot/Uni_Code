#!/bin/bash
#Author: Connor Harris 23208009
#
#   This script takes two profiles, converts word occurences to average per thousand,
#   then performs a Euclidian distance metric (sqrt(sum of all: (profile1 - profile2)^2))
#   And returns the values as a string
#   
#   This script will only be called by the overarching "style_cmp" file, so there isn't 
#   any user input checks required

#Turn the variable input into a file
echo $profile_1 | tr " " "\n" | tr ":" " " >> file_1
echo $profile_2 | tr " " "\n" | tr ":" " " >> file_2


#This script section converts and normalises all the values from both profiles (turns into avg/1,000) and puts them into one file
let profiles_count=1 #Variable to tell which profile the script is currently altering
while [[ $profiles_count -lt $((3)) ]] 
do
    #Goes through the first profile during iteration 1
    if [[ $profiles_count -eq 1 ]]; then
    word_count=$(grep -w "word" file_1 | tr -d 'word ')           #word count row as int
    sentence_count=$(grep "sentence" file_1 | tr -d 'sentence ')  #sentence count row  as int
    words_per_sentence=$(awk "BEGIN {printf \"%.3f\n\", $word_count/$sentence_count}") #Words per sentence calculation
    grep -vw "word" file_1 | grep -v "sentence" | sed 's/[^0-9]*//g' | tr " " "\n" >> words_to_normalise.txt #Takes out certain rows and keeps the column containing numbers only
    words_to_normalise_count=$(cat words_to_normalise.txt | wc -l)  #Number of remaining rows
    fi 
    #Goes through the second profile after the first iteration
    if [[ $profiles_count -eq 2 ]]; then
    word_count=$(grep -w "word" file_2 | tr -d 'word ')           #word count row as int
    sentence_count=$(grep "sentence" file_2 | tr -d 'sentence ')  #sentence count row  as int
    words_per_sentence=$(awk "BEGIN {printf \"%.3f\n\", $word_count/$sentence_count}") #Words per sentence calculation
    grep -vw "word" file_2 | grep -v "sentence" | sed 's/[^0-9]*//g' | tr " " "\n" >> words_to_normalise.txt #Takes out certain rows and keeps the column containing numbers only
    words_to_normalise_count=$(cat words_to_normalise.txt | wc -l)  #Number of remaining rows
    fi 
    #Loop to iterate through each row and normalise the value (occurences per thousand) 
    for ((i = 1 ; i <= $words_to_normalise_count ; i++)); do 
        current_num=$(head -n $i words_to_normalise.txt | tail -n 1) #Get only the required row
        if [[ $current_num > 0 ]] #If the row is greater than 0 perform calculation
        then
            awk "BEGIN {printf \"%.3f\n\", $current_num/$word_count*1000}" >> normalised_values.txt
        else 
            echo "0" >> normalised_values.txt #Add 0 value rows to avoid doing calculation on 0
        fi
    done
    echo $words_per_sentence >> normalised_values.txt #Put the words per sentence at the bottom of the calculations just performed
    sed -i '/^$/d' normalised_values.txt #remove blank rows from the file holding normalised values
    rm words_to_normalise.txt #delete file to maintain data integrity
    profiles_count=$(($profiles_count+1))
done

#Function to take each normalised value, and take the sqrt of the sum of (profile1 - profile2)^2
head -n 27 normalised_values.txt >> comparison1.txt #Split the one giant file into two sub files for side by side comparison
tail -n 27 normalised_values.txt >> comparison2.txt 
euc_calculation=$(echo 0.000) #Declare a float using pure bash

#Iterate through the two files containing normalised values and perform the Euclidian equation on them
for ((i = 1 ; i <= 27 ; i++)); do 
    profile1=$(head -n $i comparison1.txt | tail -n 1) #Get each corresponding value
    profile2=$(head -n $i comparison2.txt | tail -n 1)
    current_z=$(awk "BEGIN {printf \"%.3f\n\", ($profile1-$profile2)^2}") #(profile1 - profile2)^2
    euc_calculation=$(awk "BEGIN {printf \"%.3f\n\", ($euc_calculation+$current_z)}") #Sum all values of previous calculation step
done

#Return final value
echo "The Euclidian Distance between the two texts is: "$(awk "BEGIN {printf \"%.3f\n\", ($euc_calculation)^0.5}")

#DEL FILES AT END OF SCRIPT
rm normalised_values.txt | rm comparison1.txt | rm comparison2.txt | rm file_1 | rm file_2

#Exit sucessfully
exit 0